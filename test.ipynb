{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.special import softmax\n",
    "import collections\n",
    "\n",
    "from nats_bench import create\n",
    "from nats_bench.api_utils import time_string\n",
    "from xautodl.models import get_cell_based_tiny_net\n",
    "\n",
    "import data.cifar10 as cifar10\n",
    "import data.cifar100 as cifar100\n",
    "import data.tiny_imagenet as imagenet\n",
    "import calibration as cal\n",
    "import calibration.metric as metric\n",
    "import calibration.ece_kde as ece_kde\n",
    "import calibration.tace as tace\n",
    "from torch.utils.data import DataLoader\n",
    "from calibration.temp_scale import TemperatureScaling, NLL, BS, accuracy,logistic_func\n",
    "\n",
    "from data.datatest import get_logits_labels, get_valid_test_loader\n",
    "\n",
    "from xautodl.datasets import get_dataset_with_transform\n",
    "from xautodl.datasets.get_dataset_with_transform import get_datasets\n",
    "from calibration.temperature_scaling import ModelWithTemperature\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_and_targets(model, dataloader, device):\n",
    "    preds, pred_classes, targets = [], [], []\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    model.to(device)  # Move model to the selected device (CPU or GPU)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output_tuple = model(data)\n",
    "\n",
    "            output = output_tuple[1]\n",
    "\n",
    "            prob = F.softmax(output, dim=1)  # Compute probabilities\n",
    "            _, pred = torch.max(prob, 1)  # Get predicted class\n",
    "\n",
    "            preds.extend(prob.cpu().numpy())  # Move probabilities to CPU and convert to numpy array\n",
    "            pred_classes.extend(pred.cpu().numpy())  # Move predictions to CPU and convert to numpy array\n",
    "            targets.extend(target.cpu().numpy())  # Move targets to CPU and convert to numpy array\n",
    "\n",
    "    return np.array(preds), np.array(pred_classes), np.array(targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_and_targets2(model, dataloader, device):\n",
    "    preds, pred_classes, targets = [], [], []\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    model.to(device)  # Move model to the selected device (CPU or GPU)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output_tuple = model(data)\n",
    "\n",
    "            output = output_tuple\n",
    "\n",
    "            prob = F.softmax(output, dim=1)  # Compute probabilities\n",
    "            _, pred = torch.max(prob, 1)  # Get predicted class\n",
    "\n",
    "            preds.extend(prob.cpu().numpy())  # Move probabilities to CPU and convert to numpy array\n",
    "            targets.extend(target.cpu().numpy())  # Move targets to CPU and convert to numpy array\n",
    "\n",
    "    return np.array(preds), np.array(pred_classes), np.array(targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss_dir = \"/hdd/datasets/NATSBench/sss-full/\"\n",
    "tss_dir = \"/hdd/datasets/NATSBench/NATS-tss-v1_0-3ffb9-full-extracted/NATS-tss-v1_0-3ffb9-full/\"\n",
    "root = '/home/younan/project_calibration/datasets/ImagenNet16'\n",
    "api_type = 'tss'\n",
    "image_dataset = 'ImageNet16-120'\n",
    "archi_num = 8\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "post_temp = 'True'\n",
    "\n",
    "\n",
    "if api_type =='tss':\n",
    "    api = create(tss_dir, api_type, fast_mode=True, verbose=False)\n",
    "elif api_type =='sss':\n",
    "    api = create(sss_dir, api_type, fast_mode=True, verbose=False)\n",
    "else:\n",
    "    raise ValueError('api_type must be either tss or sss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = api.get_net_config(archi_num, image_dataset)\n",
    "archi_info = api.get_more_info(archi_num, image_dataset,hp ='200',is_random=False)\n",
    "# get the info of architecture of the 6111-th model on CIFAR-10\n",
    "net = get_cell_based_tiny_net(config)\n",
    "arch = api.arch(archi_num) \n",
    "\n",
    "# Load the pre-trained weights: params is a dict, where the key is the seed and value is the weights.\n",
    "params = api.get_net_param(archi_num, image_dataset,None, hp ='200')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(next(iter(params.values())))\n",
    "# net.load_state_dict(params[777])\n",
    "if image_dataset == 'cifar10':\n",
    "    if post_temp == 'True':\n",
    "        test_loader, val_loader = cifar10.get_test_valid_loader(batch_size = 256,\n",
    "                            random_seed = 42,\n",
    "                            valid_size=0.2,\n",
    "                            shuffle=True,\n",
    "                            num_workers=4, pin_memory=False)\n",
    "    else:\n",
    "        test_loader = cifar10.get_test_loader(batch_size=256, shuffle=False, num_workers=4, pin_memory=False)\n",
    "elif image_dataset == 'cifar100':\n",
    "    if post_temp == 'True':\n",
    "        test_loader, val_loader = cifar100.get_test_valid_loader(batch_size = 256,\n",
    "                            random_seed = 42,\n",
    "                            valid_size=0.2,\n",
    "                            shuffle=True,\n",
    "                            num_workers=4, pin_memory=False)\n",
    "    else:\n",
    "        test_loader = cifar100.get_test_loader(batch_size=256, shuffle=False, num_workers=4, pin_memory=False)\n",
    "elif image_dataset == 'ImageNet16-120':\n",
    "    \n",
    "\n",
    "    root = './datasets/ImagenNet16'\n",
    "    train_data, test_data, xshape, class_num = get_datasets(image_dataset, root, 0)\n",
    "\n",
    "    if post_temp == 'True':\n",
    "        def imagenet_get_test_valid_loader(batch_size = 256, random_seed= 42, valid_size = 0.2, shuffle = True,\n",
    "                                    num_workers=4, pin_memory=False,\n",
    "                                test_dataset=test_data):\n",
    "            num_test = len(test_dataset)\n",
    "            indices = list(range(num_test))\n",
    "            split = int(np.floor(valid_size * num_test))\n",
    "\n",
    "            if shuffle:\n",
    "                np.random.seed(random_seed)\n",
    "                np.random.shuffle(indices)\n",
    "\n",
    "            test_idx, valid_idx = indices[split:], indices[:split]\n",
    "            \n",
    "\n",
    "            test_sampler = SubsetRandomSampler(test_idx)\n",
    "            valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "            test_loader = torch.utils.data.DataLoader(\n",
    "                test_dataset, batch_size=batch_size, sampler=test_sampler,\n",
    "                num_workers=num_workers, pin_memory=pin_memory,\n",
    "            )\n",
    "            valid_loader = torch.utils.data.DataLoader(\n",
    "                test_dataset, batch_size=batch_size, sampler=valid_sampler,\n",
    "                num_workers=num_workers, pin_memory=pin_memory,\n",
    "            )\n",
    "            return test_loader, valid_loader\n",
    "        test_loader, val_loader = imagenet_get_test_valid_loader(batch_size = 256, random_seed= 42, valid_size = 0.2, shuffle = True,\n",
    "                                num_workers=4, pin_memory=False)\n",
    "    else:\n",
    "        test_loader = DataLoader(test_data, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probs, val_pred_classes, val_targets = get_preds_and_targets(net, val_loader, device)\n",
    "test_probs, test_pred_classes, test_targets = get_preds_and_targets(net, test_loader, device)\n",
    "\n",
    "# val_logits = logistic_func(val_probs)\n",
    "# test_logits = logistic_func(test_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before temperature - NLL: 2.247, ECE: 0.048\n",
      "Optimal temperature: 1.100\n",
      "After temperature - NLL: 2.231, ECE: 0.032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelWithTemperature(\n",
       "  (model): TinyNetwork(\n",
       "    TinyNetwork(C=16, N=5, L=17)\n",
       "    (stem): Sequential(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (cells): ModuleList(\n",
       "      (0-4): 5 x InferCell(\n",
       "        info :: nodes=4, inC=16, outC=16, [1<-(I0-L0) | 2<-(I0-L1,I1-L2) | 3<-(I0-L3,I1-L4,I2-L5)], |nor_conv_1x1~0|+|avg_pool_3x3~0|skip_connect~1|+|skip_connect~0|none~1|nor_conv_3x3~2|\n",
       "        (layers): ModuleList(\n",
       "          (0): ReLUConvBN(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): POOLING(\n",
       "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "          )\n",
       "          (2-3): 2 x Identity()\n",
       "          (4): Zero(C_in=16, C_out=16, stride=1)\n",
       "          (5): ReLUConvBN(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ResNetBasicblock(\n",
       "        ResNetBasicblock(inC=16, outC=32, stride=2)\n",
       "        (conv_a): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (conv_b): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (6-10): 5 x InferCell(\n",
       "        info :: nodes=4, inC=32, outC=32, [1<-(I0-L0) | 2<-(I0-L1,I1-L2) | 3<-(I0-L3,I1-L4,I2-L5)], |nor_conv_1x1~0|+|avg_pool_3x3~0|skip_connect~1|+|skip_connect~0|none~1|nor_conv_3x3~2|\n",
       "        (layers): ModuleList(\n",
       "          (0): ReLUConvBN(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): POOLING(\n",
       "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "          )\n",
       "          (2-3): 2 x Identity()\n",
       "          (4): Zero(C_in=32, C_out=32, stride=1)\n",
       "          (5): ReLUConvBN(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): ResNetBasicblock(\n",
       "        ResNetBasicblock(inC=32, outC=64, stride=2)\n",
       "        (conv_a): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (conv_b): ReLUConvBN(\n",
       "          (op): Sequential(\n",
       "            (0): ReLU()\n",
       "            (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (12-16): 5 x InferCell(\n",
       "        info :: nodes=4, inC=64, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2) | 3<-(I0-L3,I1-L4,I2-L5)], |nor_conv_1x1~0|+|avg_pool_3x3~0|skip_connect~1|+|skip_connect~0|none~1|nor_conv_3x3~2|\n",
       "        (layers): ModuleList(\n",
       "          (0): ReLUConvBN(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): POOLING(\n",
       "            (op): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "          )\n",
       "          (2-3): 2 x Identity()\n",
       "          (4): Zero(C_in=64, C_out=64, stride=1)\n",
       "          (5): ReLUConvBN(\n",
       "            (op): Sequential(\n",
       "              (0): ReLU()\n",
       "              (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lastact): Sequential(\n",
       "      (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (global_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Linear(in_features=64, out_features=120, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_model = ModelWithTemperature(net)\n",
    "scaled_model.set_temperature(val_loader,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, pred_classes,targets = get_preds_and_targets(net, test_loader, device)\n",
    "preds_logit = logistic_func(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_post, pred_classes_post,targets_post = get_preds_and_targets2(scaled_model, test_loader, device)\n",
    "preds_logit_post = logistic_func(preds_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40708333333333335"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds_logit,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40708333333333335"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds_logit_post,targets_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ece: 0.05860389422625304\n",
      "posttemp_ece: 0.02285442205378785\n"
     ]
    }
   ],
   "source": [
    "print('ece:', metric.get_ece(test_probs, test_targets))\n",
    "print('posttemp_ece:', metric.get_ece(preds_post, targets_post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nll: 0.475400347499238\n",
      "posttemp_nll: 0.45047528305782364\n"
     ]
    }
   ],
   "source": [
    "print('nll:', metric.get_nll(test_probs, test_targets))\n",
    "print('posttemp_nll:', metric.get_nll(preds_post, targets_post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_nll: 0.3032133589261297\n",
      "val_optimized_nll: 0.3026488789708914\n"
     ]
    }
   ],
   "source": [
    "print('val_nll:', metric.get_nll(val_probs, val_targets))\n",
    "print('val_optimized_nll:', metric.get_nll(val_temp_preds, val_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_ece: 0.008778117203712478\n",
      "val_optimized_ece: 0.005874584877490989\n"
     ]
    }
   ],
   "source": [
    "print('val_ece:', metric.get_ece(val_probs, val_targets))\n",
    "print('val_optimized_ece:', metric.get_ece(val_temp_preds, val_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCE: 0.24607335031032562\n",
      "cwECE: 0.010834139782901622\n",
      "sce: 0.010834139782901623\n",
      "tace: 0.009887347967537355\n",
      "ace: 0.009079010745882231\n"
     ]
    }
   ],
   "source": [
    "print('MCE:', metric.get_mce(preds, targets))\n",
    "print('cwECE:', metric.get_classwise_ece(preds, targets))\n",
    "\n",
    "print('sce:', metric.get_sce(preds, targets))\n",
    "print('tace:', metric.get_tace(preds, targets))\n",
    "print('ace:', metric.get_ace(preds, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "def get_param_dict(func, *args, **kwargs):\n",
    "    result = func(*args, **kwargs)\n",
    "    \n",
    "    # Get the function's signature and parameters\n",
    "    signature = inspect.signature(func)\n",
    "    params = signature.parameters\n",
    "\n",
    "    # Create a dictionary with default parameter values\n",
    "    default_params = {k: v.default for k, v in params.items() if v.default != inspect.Parameter.empty}\n",
    "\n",
    "    # Update the default parameter values with the provided kwargs\n",
    "    all_params = {**default_params, **kwargs}\n",
    "    \n",
    "    all_params['result'] = result\n",
    "    return all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ole: 0.037136059674976026\n"
     ]
    }
   ],
   "source": [
    "ole_loss = tace.OELoss()\n",
    "ole = ole_loss.loss(preds, targets, n_bins=15,logits = False)\n",
    "ole_str = str(get_param_dict(ole_loss.loss, preds, targets, n_bins=15,logits = False)) + ', '\n",
    "print('ole:', ole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sce: 0.8778040399349889\n",
      "tace: 0.0864724029721599\n",
      "ace: 0.0864724029721599\n"
     ]
    }
   ],
   "source": [
    "sce_loss = tace.SCELoss()\n",
    "tace_loss = tace.TACELoss()\n",
    "ace_loss = tace.ACELoss()\n",
    "sce = sce_loss.loss(preds, targets, n_bins=15,logits = False)\n",
    "tace = tace_loss.loss(preds, targets, n_bins=15,logits = False)\n",
    "ace = ace_loss.loss(preds, targets, n_bins=15,logits = False)\n",
    "print('sce:', sce)\n",
    "print('tace:', tace)\n",
    "print('ace:', ace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ece_data = get_param_dict(metric.get_ece, preds, targets,n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_bins': 15, 'result': 0.046477467873692516}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ece_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bin = 10\n",
    "ece_data = get_param_dict(metric.get_ece, preds, targets,n_bins=n_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_bins': 10, 'result': 0.046477467873692516}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ece_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCE_debias: 0.04650807754683169\n",
      "Marginal_CE_debias: 0.009360044983501115\n",
      "TCE: 0.046481831607222544\n",
      "Marginal_CE: 0.009520283665955068\n",
      "ECE_em: 0.046481831607222544\n"
     ]
    }
   ],
   "source": [
    "print('TCE_debias:', cal.get_top_calibration_error(preds, targets,p=1))\n",
    "print('Marginal_CE_debias:', cal.get_calibration_error(preds, targets,p=1))\n",
    "print('TCE:', cal.get_top_calibration_error(preds, targets,debias=False,p=1))\n",
    "print('Marginal_CE:', cal.get_calibration_error(preds, targets,debias=False,p=1))\n",
    "print('ECE_em:', cal.get_ece_em(preds, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KSCE: 0.04648401403427127\n",
      "KDECE: 0.04269384100094596\n",
      "MMCE: 0.037466022106703564\n",
      "NLL: 0.9962960859691724\n",
      "brier: 0.022643672204411006\n"
     ]
    }
   ],
   "source": [
    "print('KSCE:', metric.get_KSCE(preds, targets))\n",
    "print('KDECE:', metric.get_KDECE(preds, targets))\n",
    "print('MMCE:', metric.get_MMCE(preds, targets))\n",
    "print('NLL:', metric.get_nll(preds, targets))\n",
    "print('brier:', metric.get_brierscore(preds, targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_sizes = [5,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ece_str = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for n_bins in bin_sizes:\n",
    "    ece_str += str(get_param_dict(metric.get_ece, preds, targets, n_bins)) + ', '\n",
    "    print(n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.73 GiB (GPU 0; 10.76 GiB total capacity; 7.45 GiB already allocated; 676.25 MiB free; 7.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-3aab36a6c924>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ECE_KDE:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mece_kde\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ece_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbandwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'marginal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/project_calibration/calibration/ece_kde.py\u001b[0m in \u001b[0;36mget_ece_kde\u001b[0;34m(f, y, bandwidth, p, mc_type, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_ratio_canonical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmc_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'marginal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_ratio_marginal_vect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmc_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'top_label'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_ratio_toplabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project_calibration/calibration/ece_kde.py\u001b[0m in \u001b[0;36mget_ratio_marginal_vect\u001b[0;34m(f, y, bandwidth, p, device)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_ratio_marginal_vect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0my_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mlog_kern_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0mlog_kern_diag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m# Multiclass case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project_calibration/calibration/ece_kde.py\u001b[0m in \u001b[0;36mbeta_kernel\u001b[0;34m(z, zi, bandwidth)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mlog_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     \u001b[0mlog_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0mlog_beta_pdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_num\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlog_beta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.73 GiB (GPU 0; 10.76 GiB total capacity; 7.45 GiB already allocated; 676.25 MiB free; 7.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "tensor_preds = torch.tensor(preds).to(device)\n",
    "tensor_targets = torch.tensor(targets).to(device)\n",
    "    \n",
    "\n",
    "print('ECE_KDE:', ece_kde.get_ece_kde(tensor_preds, tensor_targets, bandwidth = 0.001, p = 1, mc_type = 'marginal', device = device).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE_KDE: 0.24982665479183197\n"
     ]
    }
   ],
   "source": [
    "tensor_preds = torch.tensor(preds).to(device)\n",
    "tensor_targets = torch.tensor(targets).to(device)\n",
    "\n",
    "\n",
    "print('ECE_KDE:', ece_kde.get_ece_kde(tensor_preds, tensor_targets, bandwidth = 0.001, p = 1, mc_type = 'canonical', device = device).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandiwitdh = ece_kde.get_bandwidth(tensor_preds, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0010)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandiwitdh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_kern = ece_kde.get_kernel(f =tensor_preds, bandwidth=0.001, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_kern = ece_kde.get_kernel(f =tensor_preds, bandwidth=0.001, device = device)\n",
    "kern = torch.exp(log_kern)\n",
    "\n",
    "y_onehot = nn.functional.one_hot(tensor_targets, num_classes=tensor_preds.shape[1]).to(torch.float32)\n",
    "kern_y = torch.matmul(kern, y_onehot)\n",
    "den = torch.sum(kern, dim=1)\n",
    "# to avoid division by 0\n",
    "den = torch.clamp(den, min=1e-10)\n",
    "\n",
    "ratio = kern_y / den.unsqueeze(-1)\n",
    "ratio = torch.sum(torch.abs(ratio - tensor_preds)**1, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2498, device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratio.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_preds.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1602)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.rand((50, 3))\n",
    "f = f / torch.sum(f, dim=1).unsqueeze(-1)\n",
    "y = torch.randint(0, 3, (50,))\n",
    "\n",
    "ece_kde.get_ece_kde(f, y, bandwidth=0.001, p=1, mc_type='canonical', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE_KDE: tensor(nan, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "tensor_preds = torch.tensor(preds).to(device)\n",
    "tensor_targets = torch.tensor(targets).to(device)\n",
    "    \n",
    "\n",
    "print('ECE_KDE:', ece_kde.get_ece_kde(tensor_preds, tensor_targets, bandwidth = 0.001, p = 2, mc_type = 'top_label', device = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 8,  ..., 5, 1, 7], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_preds.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
