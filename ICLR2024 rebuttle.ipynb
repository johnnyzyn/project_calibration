{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import argparse\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# from scipy.special import softmax\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "\n",
    "import data.cifar10 as cifar10\n",
    "import data.cifar100 as cifar100\n",
    "import calibration as cal\n",
    "import calibration.metric as metric\n",
    "import calibration.tace as tace\n",
    "from xautodl.datasets.get_dataset_with_transform import get_datasets\n",
    "from torch.utils.data import DataLoader\n",
    "# import calibration.ece_kde as ece_kde\n",
    "import inspect\n",
    "\n",
    "from calibration.temperature_scaling import ModelWithTemperature\n",
    "from calibration.temp_scale import accuracy\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from Net.resnet_tiny_imagenet import resnet50 as resnet50_ti\n",
    "from Net.resnet import resnet18,resnet34,resnet50, resnet110\n",
    "from Net.wide_resnet import wide_resnet_cifar\n",
    "from Net.densenet import densenet121\n",
    "\n",
    "import os\n",
    "\n",
    "# Import metrics to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_and_targets(model, dataloader, device):\n",
    "    preds, pred_classes, targets = [], [], []\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    model.to(device)  # Move model to the selected device (CPU or GPU)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output_tuple = model(data)\n",
    "\n",
    "            output = output_tuple[1]\n",
    "\n",
    "            prob = F.softmax(output, dim = 1)  # Compute probabilities\n",
    "            _, pred = torch.max(prob, 1)  # Get predicted class\n",
    "\n",
    "            preds.extend(prob.cpu().numpy())  # Move probabilities to CPU and convert to numpy array\n",
    "            pred_classes.extend(pred.cpu().numpy())  # Move predictions to CPU and convert to numpy array\n",
    "            targets.extend(target.cpu().numpy())  # Move targets to CPU and convert to numpy array\n",
    "\n",
    "    return np.array(preds), np.array(pred_classes), np.array(targets)\n",
    "\n",
    "def get_preds_and_targets2(model, dataloader, device):\n",
    "    #use this when using temp scale since the network output is logits not tuple \n",
    "\n",
    "    preds, pred_classes, targets = [], [], []\n",
    "\n",
    "    model.eval()  \n",
    "    model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output_tuple = model(data)\n",
    "\n",
    "            output = output_tuple\n",
    "            \n",
    "            prob = F.softmax(output, dim=1)\n",
    "            _, pred = torch.max(prob, 1)\n",
    "\n",
    "            preds.extend(prob.cpu().numpy())  # Move probabilities to CPU and convert to numpy array\n",
    "            targets.extend(target.cpu().numpy())  # Move targets to CPU and convert to numpy array\n",
    "\n",
    "    return np.array(preds), np.array(pred_classes), np.array(targets)\n",
    "\n",
    "def get_param_dict(func, *args, **kwargs):\n",
    "    result = func(*args, **kwargs)\n",
    "    \n",
    "    # Get the function's signature and parameters\n",
    "    signature = inspect.signature(func)\n",
    "    params = signature.parameters\n",
    "\n",
    "    # Create a dictionary with default parameter values\n",
    "    default_params = {k: v.default for k, v in params.items() if v.default != inspect.Parameter.empty}\n",
    "\n",
    "    # Update the default parameter values with the provided kwargs\n",
    "    all_params = {**default_params, **kwargs}\n",
    "    \n",
    "    all_params['result'] = result\n",
    "    return all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logits_labels(data_loader, net,device):\n",
    "    logits_list = []\n",
    "    labels_list = []\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, label in data_loader:\n",
    "            data = data.to(device)\n",
    "            logits = net(data)\n",
    "            logits_list.append(logits)\n",
    "            labels_list.append(label)\n",
    "        logits = torch.cat(logits_list).to(device)\n",
    "        labels = torch.cat(labels_list).to(device)\n",
    "    return logits, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'resnet18': resnet18\n",
    "    # ,\n",
    "    # 'resnet34': resnet34,\n",
    "    # 'resnet50': resnet50,\n",
    "    # 'resnet110': resnet110,\n",
    "    # 'wide_resnet': wide_resnet_cifar,\n",
    "    # 'densenet121': densenet121\n",
    "}\n",
    "\n",
    "dataset_num_classes = {\n",
    "    'cifar10': 10,\n",
    "    'cifar100': 100,\n",
    "    'ImageNet16-120': 120\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Argument parser setup\n",
    "    # parser = argparse.ArgumentParser(description=\"Model evaluation and result storage\")\n",
    "    # parser.add_argument(\"--csv_file\", type=str, default=\"results.csv\", help=\"CSV file name to store or update results\")\n",
    "    # parser.add_argument(\"--bin_sizes\", type=int, default=[5, 10,15,20,25,50,100,200,500], help=\"Number of bins for calibration metrics\")\n",
    "\n",
    "    # parser.add_argument(\"--image_dataset\", type=str, default=\"cifar10\", help=\"CIFAR-10, CIFAR-100, and ImageNet16-120\")\n",
    "    # parser.add_argument(\"--post_temp\", type=str, default='False', help=\"if using temp scale\")\n",
    "    # parser.add_argument(\"--device\", type=str, default='cuda:0', help=\"device\")\n",
    "    # parser.add_argument(\"--dataset\", type=str, default='cifar10',\n",
    "    #                     dest=\"dataset\", help='dataset to test on')\n",
    "    # parser.add_argument(\"--save-path\", type=str, default=save_loc,\n",
    "    #                     dest=\"save_loc\",\n",
    "    #                     help='Path to import the model')\n",
    "    # parser.add_argument(\"--saved_model_name\", type=str, default=saved_model_name,\n",
    "    #                     dest=\"saved_model_name\", help=\"file name of the pre-trained model\")\n",
    "\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "\n",
    "    # Use the parsed arguments\n",
    "    csv_file = \"results.csv\"\n",
    "    bin_sizes = [5, 10, 15, 20, 25, 50, 100, 200, 500]\n",
    "    image_dataset = \"cifar10\"\n",
    "    post_temp = 'False'\n",
    "    device = 'cuda:2' if torch.cuda.is_available() else \"cpu\"\n",
    "    dataset = 'cifar100'\n",
    "    save_loc = './'\n",
    "    saved_model_name = 'resnet18_cross_entropy.model'\n",
    "\n",
    "    num_classes = dataset_num_classes[dataset]\n",
    "\n",
    "    model_dir = \"/home/younan/project_calibration/project_calibration/MODEL_DIRECTORY/\"\n",
    "\n",
    "    for model_name in models:\n",
    "        model = models[model_name]\n",
    "\n",
    "        net = model(num_classes=num_classes, temp=1.0)\n",
    "        # net.cuda()\n",
    "        net.to(device)\n",
    "        # net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "        cudnn.benchmark = True\n",
    "        # Load the state dict from the file\n",
    "        state_dict = torch.load(model_dir + saved_model_name)\n",
    "\n",
    "        # Remove the 'module.' prefix\n",
    "        new_state_dict = {k[len(\"module.\"):]: v for k, v in state_dict.items()}\n",
    "\n",
    "        # Load the adjusted state dict into your model\n",
    "        net.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "post_temp = 'True'\n",
    "\n",
    "if dataset == 'cifar10':\n",
    "    if post_temp == 'True':\n",
    "        test_loader, val_loader = cifar10.get_test_valid_loader(batch_size = 256,\n",
    "                            random_seed = 42,\n",
    "                            valid_size=0.2,\n",
    "                            shuffle=True,\n",
    "                            num_workers=4, pin_memory=False)\n",
    "    else:\n",
    "        test_loader = cifar10.get_test_loader(batch_size=256, shuffle=False, num_workers=4, pin_memory=False)\n",
    "elif dataset == 'cifar100':\n",
    "    if post_temp == 'True':\n",
    "        test_loader, val_loader = cifar100.get_test_valid_loader(batch_size = 256,\n",
    "                            random_seed = 42,\n",
    "                            valid_size=0.2,\n",
    "                            shuffle=True,\n",
    "                            num_workers=4, pin_memory=False)\n",
    "    else:\n",
    "        test_loader = cifar100.get_test_loader(batch_size=256, shuffle=False, num_workers=4, pin_memory=False)\n",
    "elif dataset == 'ImageNet16-120':\n",
    "    \n",
    "\n",
    "    root = './datasets/ImagenNet16'\n",
    "    train_data, test_data, xshape, class_num = get_datasets(image_dataset, root, 0)\n",
    "\n",
    "    if post_temp == 'True':\n",
    "        def imagenet_get_test_valid_loader(batch_size = 256, random_seed= 42, valid_size = 0.2, shuffle = True,\n",
    "                                    num_workers=4, pin_memory=False,\n",
    "                                test_dataset=test_data):\n",
    "            num_test = len(test_dataset)\n",
    "            indices = list(range(num_test))\n",
    "            split = int(np.floor(valid_size * num_test))\n",
    "\n",
    "            if shuffle:\n",
    "                np.random.seed(random_seed)\n",
    "                np.random.shuffle(indices)\n",
    "\n",
    "            test_idx, valid_idx = indices[split:], indices[:split]\n",
    "            \n",
    "\n",
    "            test_sampler = SubsetRandomSampler(test_idx)\n",
    "            valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "            test_loader = torch.utils.data.DataLoader(\n",
    "                test_dataset, batch_size=batch_size, sampler=test_sampler,\n",
    "                num_workers=num_workers, pin_memory=pin_memory,\n",
    "            )\n",
    "            valid_loader = torch.utils.data.DataLoader(\n",
    "                test_dataset, batch_size=batch_size, sampler=valid_sampler,\n",
    "                num_workers=num_workers, pin_memory=pin_memory,\n",
    "            )\n",
    "            return test_loader, valid_loader\n",
    "        test_loader, val_loader = imagenet_get_test_valid_loader(batch_size = 256, random_seed= 42, valid_size = 0.2, shuffle = True,\n",
    "                                num_workers=4, pin_memory=False)\n",
    "    else:\n",
    "        test_loader = DataLoader(test_data, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, labels = get_logits_labels(test_loader, net,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, labels = get_logits_labels(val_loader, net,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2115, -3.0624,  1.0376,  ..., -0.1389,  0.9347,  1.0207],\n",
       "        [ 0.2889,  2.0660, -2.4687,  ..., -4.0581, -3.8591, -1.1131],\n",
       "        [-1.6086, -1.1720,  0.4942,  ...,  1.8165, -0.1948,  0.4138],\n",
       "        ...,\n",
       "        [-2.2142,  1.6175,  0.2877,  ...,  0.6096,  0.6216,  0.9865],\n",
       "        [-2.4944, -1.3995, -1.6311,  ..., -0.0470, -2.7177,  0.5685],\n",
       "        [-0.7392,  1.6196, -0.4817,  ...,  0.9357, -0.3500, -0.2709]],\n",
       "       device='cuda:2')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before temperature - NLL: 3.604, ECE: 0.040\n",
      "Optimal temperature: 1.200\n",
      "After temperature - NLL: 3.588, ECE: 0.026\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if post_temp == 'True':\n",
    "    val_probs, val_pred_classes, val_targets = get_preds_and_targets2(net, val_loader, device)\n",
    "    test_probs, test_pred_classes, test_targets = get_preds_and_targets2(net, test_loader, device)\n",
    "\n",
    "    scaled_model = ModelWithTemperature(net)\n",
    "    scaled_model.set_temperature(val_loader,device=device)\n",
    "\n",
    "    preds, pred_classes,targets  = get_preds_and_targets2(scaled_model, test_loader, device)\n",
    "else:\n",
    "\n",
    "    preds, pred_classes,targets = get_preds_and_targets2(net, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  config     info   dataset  \\\n",
      "0  <function resnet18 at 0x7fa1280b2b80>  0.13625  cifar100   \n",
      "\n",
      "                                                 ece  \\\n",
      "0  {'n_bins': 5, 'result': 0.009811824304051702},...   \n",
      "\n",
      "                                                 sce  \\\n",
      "0  {'n_bins': 5, 'logits': False, 'result': 0.003...   \n",
      "\n",
      "                                                tace  \\\n",
      "0  {'n_bins': 5, 'threshold': 0.001, 'logits': Fa...   \n",
      "\n",
      "                                                 ace  \\\n",
      "0  {'n_bins': 5, 'logits': False, 'result': 0.003...   \n",
      "\n",
      "                                                 MCE  \\\n",
      "0  {'n_bins': 5, 'result': 0.19718930721282957}, ...   \n",
      "\n",
      "                                               cwECE  \\\n",
      "0  {'n_bins': 5, 'result': 0.00337140131123364}, ...   \n",
      "\n",
      "                                  Marginal_CE_debias  \\\n",
      "0  {'p': 1, 'debias': True, 'mode': 'marginal', '...   \n",
      "\n",
      "                                         Marginal_CE  \\\n",
      "0  {'p': 1, 'debias': False, 'mode': 'marginal', ...   \n",
      "\n",
      "                                              ECE_em  \\\n",
      "0  {'debias': False, 'num_bins': 5, 'mode': 'top-...   \n",
      "\n",
      "                                                 Ole  \\\n",
      "0  {'n_bins': 500, 'logits': False, 'result': 0.0...   \n",
      "\n",
      "                               KSCE  \\\n",
      "0  {'result': 0.005082654118537894}   \n",
      "\n",
      "                                               KDECE  \\\n",
      "0  {'p_int': None, 'order': 1, 'result': 0.018063...   \n",
      "\n",
      "                               MMCE                             NLL  \\\n",
      "0  {'result': 0.005785939557031095}  {'result': 3.5822642814289174}   \n",
      "\n",
      "                              brier                  timestamp  \n",
      "0  {'result': 0.009396664867948634} 2023-11-12 12:30:14.829460  \n"
     ]
    }
   ],
   "source": [
    "ece_str = ''\n",
    "sce_str = ''\n",
    "tace_str = ''\n",
    "ace_str = ''\n",
    "mce_str = ''\n",
    "cwECE_str = ''\n",
    "ECE_em_str = ''\n",
    "ole_str = ''\n",
    "ole_loss = tace.OELoss()\n",
    "\n",
    "for n_bin in bin_sizes:\n",
    "    ece_str += str(get_param_dict(metric.get_ece, preds, targets, n_bins=n_bin)) + ', '\n",
    "    sce_str += str(get_param_dict(metric.get_sce,preds, targets, n_bins=n_bin,logits = False)) + ', '\n",
    "    tace_str += str(get_param_dict(metric.get_tace,preds, targets, n_bins=n_bin,logits = False)) + ', '\n",
    "    ace_str += str(get_param_dict(metric.get_ace,preds, targets, n_bins=n_bin,logits = False)) + ', '\n",
    "    mce_str += str(get_param_dict(metric.get_mce, preds, targets, n_bins=n_bin)) + ', '\n",
    "    cwECE_str += str(get_param_dict(metric.get_classwise_ece, preds, targets, n_bins=n_bin)) + ', '\n",
    "    ECE_em_str += str(get_param_dict(cal.get_ece_em, preds, targets, num_bins=n_bin)) + ', '\n",
    "    ole_str = str(get_param_dict(ole_loss.loss, preds, targets, n_bins=n_bin,logits = False)) + ', '\n",
    "\n",
    "# Remove the trailing comma and space\n",
    "ece_str = ece_str.rstrip(', ')\n",
    "sce_str = sce_str.rstrip(', ')\n",
    "tace_str = tace_str.rstrip(', ')\n",
    "ace_str = ace_str.rstrip(', ')\n",
    "mce_str = mce_str.rstrip(', ')\n",
    "cwECE_str = cwECE_str.rstrip(', ')\n",
    "ECE_em_str = ECE_em_str.rstrip(', ')\n",
    "ole_str = ole_str.rstrip(', ')\n",
    "\n",
    "data = {\n",
    "    'config': [model],\n",
    "    'info' : [accuracy(preds,targets)],\n",
    "    'dataset': [dataset],\n",
    "    'ece': ece_str,\n",
    "    'sce': sce_str,\n",
    "    'tace': tace_str,\n",
    "    'ace': ace_str,\n",
    "    'MCE': mce_str,\n",
    "    'cwECE': cwECE_str,\n",
    "    'Marginal_CE_debias': [get_param_dict(cal.get_calibration_error,preds, targets,p=1)],\n",
    "    'Marginal_CE': [get_param_dict(cal.get_calibration_error,preds, targets, debias=False,p=1)],\n",
    "    'ECE_em': ECE_em_str,\n",
    "    'Ole': ole_str,\n",
    "    'KSCE': [get_param_dict(metric.get_KSCE,preds, targets)],\n",
    "    'KDECE': [get_param_dict(metric.get_KDECE,preds, targets)],\n",
    "    'MMCE': [get_param_dict(metric.get_MMCE,preds, targets)],\n",
    "    'NLL': [get_param_dict(metric.get_nll,preds, targets)],\n",
    "    'brier': [get_param_dict(metric.get_brierscore,preds, targets)],\n",
    "    # 'ECE_KDE': [get_param_dict(ece_kde.get_ece_kde(tensor_preds, tensor_targets, bandwidth=bandwidth, p=1, mc_type='canonical', device=device).item())],\n",
    "    'timestamp': [datetime.datetime.now()]\n",
    "}\n",
    "\n",
    "# print(data)\n",
    "# Step 2: Convert the dictionary into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
